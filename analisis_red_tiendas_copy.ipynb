{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Rendimiento de Tiendas - RetailNow\n",
    "\n",
    "**Objetivo:** Este notebook tiene como finalidad analizar los datos de ventas, inventarios y satisfacción del cliente de la empresa ficticia RetailNow. El propósito es procesar, explorar y analizar estos datos utilizando las librerías **Pandas** y **Numpy** para extraer información valiosa que ayude a la dirección a tomar decisiones estratégicas sobre la optimización del rendimiento de las tiendas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación del Entorno\n",
    "\n",
    "El primer paso es importar las librerías necesarias para el análisis de datos. Utilizaremos **Pandas** para la manipulación y análisis de datos tabulares y **Numpy** para operaciones numéricas eficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Librerías importadas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Limpieza de Datos\n",
    "\n",
    "A continuación, cargaremos los datos desde los archivos CSV proporcionados: `sales.csv`, `inventories.csv` y `satisfaction.csv`.\n",
    "\n",
    "Para asegurar la calidad de los datos y trabajar únicamente con registros válidos, eliminaremos las filas que contengan valores nulos (`NaN`) utilizando el método `dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos CSV cargados correctamente.\n",
      "\n",
      "--- Antes de la limpieza ---\n",
      "Filas en df_sales: 10\n",
      "\n",
      "--- Después de la limpieza ---\n",
      "Filas en df_sales: 10\n",
      "Datos limpios y listos para el análisis.\n"
     ]
    }
   ],
   "source": [
    "# Definir las rutas absolutas de los archivos CSV\n",
    "path_sales = './sales.csv'\n",
    "path_inventories = './inventories.csv'\n",
    "path_satisfaction = './satisfaction.csv'\n",
    "\n",
    "# Cargar los datos en DataFrames de Pandas\n",
    "try:\n",
    "    df_sales = pd.read_csv(path_sales)\n",
    "    df_inventories = pd.read_csv(path_inventories)\n",
    "    df_satisfaction = pd.read_csv(path_satisfaction)\n",
    "    print(\"Archivos CSV cargados correctamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: No se encontraron los archivos CSV en las rutas especificadas.\")\n",
    "    # NOTA: Como este entorno no tiene acceso a los archivos, \n",
    "    # se crearán DataFrames de ejemplo para permitir la ejecución del código.\n",
    "    data_sales = {\n",
    "        'tienda_id': [1, 1, 2, 2, 3, 3, 1, 4, 4, 5, 5, 2],\n",
    "        'producto_id': [101, 102, 101, 103, 102, 103, 101, 104, 101, 105, 102, 103],\n",
    "        'categoria': ['Electronica', 'Hogar', 'Electronica', 'Ropa', 'Hogar', 'Ropa', 'Electronica', 'Juguetes', 'Electronica', 'Deportes', 'Hogar', 'Ropa'],\n",
    "        'cantidad_vendida': [20, 15, 18, 30, 25, 22, 30, 40, 12, 15, 10, np.nan],\n",
    "        'precio_unitario': [150.0, 45.5, 150.0, 25.0, 45.5, 25.0, 150.0, 15.0, 150.0, 80.0, 45.5, 25.0]\n",
    "    }\n",
    "    data_inventories = {\n",
    "        'tienda_id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
    "        'producto_id': [101, 102, 101, 103, 102, 103, 104, 101, 105, 102],\n",
    "        'stock_disponible': [150, 200, 120, 300, 250, 200, 500, 80, 90, 40]\n",
    "    }\n",
    "    data_satisfaction = {\n",
    "        'tienda_id': [1, 2, 3, 4, 5],\n",
    "        'satisfaccion_media': [85, 55, 92, 76, 59]\n",
    "    }\n",
    "    df_sales = pd.DataFrame(data_sales)\n",
    "    df_inventories = pd.DataFrame(data_inventories)\n",
    "    df_satisfaction = pd.DataFrame(data_satisfaction)\n",
    "    print(\"Se han creado DataFrames de ejemplo para la demostración.\")\n",
    "\n",
    "# --- Limpieza de Datos ---\n",
    "print(\"\\n--- Antes de la limpieza ---\")\n",
    "print(f\"Filas en df_sales: {len(df_sales)}\")\n",
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df_sales.dropna(inplace=True)\n",
    "df_inventories.dropna(inplace=True)\n",
    "df_satisfaction.dropna(inplace=True)\n",
    "\n",
    "print(\"\\n--- Después de la limpieza ---\")\n",
    "print(f\"Filas en df_sales: {len(df_sales)}\")\n",
    "print(\"Datos limpios y listos para el análisis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploración de Datos de Ventas\n",
    "\n",
    "En esta sección, realizaremos un análisis exploratorio de los datos de ventas para entender el rendimiento de la empresa.\n",
    "\n",
    "1.  **Ingresos totales**: Calcularemos los ingresos totales por transacción multiplicando la cantidad vendida por el precio unitario.\n",
    "2.  **Ventas por tienda y producto**: Agruparemos los datos para obtener las ventas totales por tienda y por producto.\n",
    "3.  **Resumen estadístico**: Generaremos un resumen estadístico para obtener métricas clave de los ingresos.\n",
    "4.  **Ventas por categoría**: Calcularemos el promedio de ventas por tienda y categoría de producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ventas Totales por Tienda ---\n",
      "   ID_Tienda  Ingresos_Totales\n",
      "0          1              5000\n",
      "1          2             10500\n",
      "2          3              9000\n",
      "3          4             13000\n",
      "4          5             13000\n",
      "\n",
      "--- Ventas Totales por Producto ---\n",
      "     Producto  Ingresos_Totales\n",
      "0  Producto A              8500\n",
      "1  Producto B             15000\n",
      "2  Producto C             27000\n",
      "\n",
      "--- Resumen Estadístico de Ingresos ---\n",
      "count       10.000000\n",
      "mean      5050.000000\n",
      "std       3361.960407\n",
      "min       1000.000000\n",
      "25%       2625.000000\n",
      "50%       3500.000000\n",
      "75%       7875.000000\n",
      "max      10500.000000\n",
      "Name: Ingresos_Totales, dtype: float64\n",
      "\n",
      "--- Promedio de Ventas por Tienda y Categoría ---\n",
      "   ID_Tienda  Ingresos_Totales\n",
      "0          1            2500.0\n",
      "1          2            5250.0\n",
      "2          3            4500.0\n",
      "3          4            6500.0\n",
      "4          5            6500.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcular los ingresos totales por transacción\n",
    "df_sales['Ingresos_Totales'] = df_sales['Cantidad_Vendida'] * df_sales['Precio_Unitario']\n",
    "\n",
    "# 2. Calcular las ventas totales por tienda y por producto usando groupby()\n",
    "ventas_por_tienda = df_sales.groupby('ID_Tienda')['Ingresos_Totales'].sum().reset_index()\n",
    "ventas_por_producto = df_sales.groupby('Producto')['Ingresos_Totales'].sum().reset_index()\n",
    "\n",
    "print(\"--- Ventas Totales por Tienda ---\")\n",
    "print(ventas_por_tienda)\n",
    "\n",
    "print(\"\\n--- Ventas Totales por Producto ---\")\n",
    "print(ventas_por_producto)\n",
    "\n",
    "# 3. Generar un resumen estadístico de los ingresos\n",
    "print(\"\\n--- Resumen Estadístico de Ingresos ---\")\n",
    "print(df_sales['Ingresos_Totales'].describe())\n",
    "\n",
    "# 4. Calcular el promedio de ventas por tienda y categoría\n",
    "ventas_por_categoria = df_sales.groupby(['ID_Tienda'])['Ingresos_Totales'].mean().reset_index()\n",
    "\n",
    "print(\"\\n--- Promedio de Ventas por Tienda y Categoría ---\")\n",
    "print(ventas_por_categoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis de Inventarios\n",
    "\n",
    "Una gestión eficiente del inventario es clave para el éxito. En esta sección, analizaremos la rotación de inventarios y detectaremos tiendas con niveles críticos.\n",
    "\n",
    "1.  **Rotación de inventario**: Calcularemos la rotación dividiendo la cantidad de unidades vendidas por el stock disponible de cada producto. El resultado se guardará en una nueva columna.\n",
    "2.  **Niveles críticos**: Filtraremos las tiendas donde la rotación de inventario sea inferior al 10%, lo que indica un posible exceso de stock o bajas ventas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Análisis de Rotación de Inventario ---\n",
      "   ID_Tienda    Producto  Stock_Disponible Fecha_Actualización  \\\n",
      "0          1  Producto A                50          2023-01-05   \n",
      "1          1  Producto B                40          2023-01-06   \n",
      "2          2  Producto A                60          2023-01-07   \n",
      "3          2  Producto C                45          2023-01-08   \n",
      "4          3  Producto A                30          2023-01-09   \n",
      "5          3  Producto B                80          2023-01-10   \n",
      "6          4  Producto C                70          2023-01-11   \n",
      "7          4  Producto A                50          2023-01-12   \n",
      "8          5  Producto B                40          2023-01-13   \n",
      "9          5  Producto C                60          2023-01-14   \n",
      "\n",
      "   Cantidad_Vendida  Rotacion_Inventario  \n",
      "0                20             0.400000  \n",
      "1                15             0.375000  \n",
      "2                30             0.500000  \n",
      "3                25             0.555556  \n",
      "4                10             0.333333  \n",
      "5                40             0.500000  \n",
      "6                35             0.500000  \n",
      "7                25             0.500000  \n",
      "8                20             0.500000  \n",
      "9                30             0.500000  \n",
      "\n",
      "--- Tiendas con Niveles Críticos de Inventario (Rotación < 10%) ---\n",
      "No se encontraron tiendas con niveles críticos de inventario.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90634/3447279262.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_inventario_analisis['Cantidad_Vendida'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Calcular el total de unidades vendidas por tienda y producto\n",
    "unidades_vendidas = df_sales.groupby(['ID_Tienda', 'Producto'])['Cantidad_Vendida'].sum().reset_index()\n",
    "\n",
    "# Unir los datos de inventario con las unidades vendidas\n",
    "df_inventario_analisis = pd.merge(df_inventories, unidades_vendidas, on=['ID_Tienda', 'Producto'], how='left')\n",
    "\n",
    "# Rellenar con 0 las ventas de productos que no se vendieron para evitar errores\n",
    "df_inventario_analisis['Cantidad_Vendida'].fillna(0, inplace=True)\n",
    "\n",
    "# 1. Calcular la rotación de inventarios\n",
    "df_inventario_analisis['Rotacion_Inventario'] = df_inventario_analisis['Cantidad_Vendida'] / df_inventario_analisis['Stock_Disponible']\n",
    "\n",
    "print(\"--- Análisis de Rotación de Inventario ---\")\n",
    "print(df_inventario_analisis)\n",
    "\n",
    "# 2. Filtrar tiendas con niveles críticos de inventario (rotación < 10%)\n",
    "inventario_critico = df_inventario_analisis[df_inventario_analisis['Rotacion_Inventario'] < 0.1]\n",
    "\n",
    "print(\"\\n--- Tiendas con Niveles Críticos de Inventario (Rotación < 10%) ---\")\n",
    "if inventario_critico.empty:\n",
    "    print(\"No se encontraron tiendas con niveles críticos de inventario.\")\n",
    "else:\n",
    "    print(inventario_critico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de Satisfacción del Cliente\n",
    "\n",
    "La satisfacción del cliente es un indicador fundamental del rendimiento. Aquí, relacionaremos los datos de satisfacción con las ventas y filtraremos las tiendas con bajo rendimiento para proponer mejoras.\n",
    "\n",
    "- **Identificación**: Filtraremos las tiendas con una satisfacción media inferior al 60%.\n",
    "- **Recomendaciones**: Basado en los resultados, propondremos acciones estratégicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tienda_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90634/1981334340.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Unir los datos de satisfacción con las ventas totales por tienda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_rendimiento_tiendas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mventas_por_tienda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_satisfaction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tienda_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Rendimiento General de Tiendas (Ventas y Satisfacción) ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rendimiento_tiendas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.13/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tienda_id'"
     ]
    }
   ],
   "source": [
    "# Unir los datos de satisfacción con las ventas totales por tienda\n",
    "df_rendimiento_tiendas = pd.merge(ventas_por_tienda, df_satisfaction, on='ID_Tienda')\n",
    "\n",
    "print(\"--- Rendimiento General de Tiendas (Ventas y Satisfacción) ---\")\n",
    "print(df_rendimiento_tiendas)\n",
    "\n",
    "# Filtrar tiendas con baja satisfacción (< 60%)\n",
    "tiendas_baja_satisfaccion = df_rendimiento_tiendas[df_rendimiento_tiendas['Satisfaccion_Media'] < 60]\n",
    "\n",
    "print(\"\\n--- Tiendas con Niveles Bajos de Satisfacción (< 60%) ---\")\n",
    "if tiendas_baja_satisfaccion.empty:\n",
    "    print(\"Todas las tiendas tienen un nivel de satisfacción adecuado.\")\n",
    "else:\n",
    "    print(tiendas_baja_satisfaccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomendaciones Estratégicas\n",
    "\n",
    "Para las tiendas identificadas con una satisfacción inferior al 60%, se recomienda:\n",
    "\n",
    "1.  **Investigación Local**: Realizar encuestas o grupos focales en esas tiendas para identificar las causas raíz de la insatisfacción (ej. calidad del servicio, disponibilidad de producto, limpieza).\n",
    "2.  **Capacitación del Personal**: Implementar programas de formación en atención al cliente para el personal de las sucursales afectadas.\n",
    "3.  **Revisión de Operaciones**: Analizar si los problemas de inventario crítico están correlacionados con la baja satisfacción, ya que la falta de productos deseados es una causa común de descontento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Operaciones Avanzadas con Numpy\n",
    "\n",
    "Finalmente, utilizaremos **Numpy** para realizar cálculos numéricos avanzados sobre los datos de ventas agregados.\n",
    "\n",
    "1.  **Cálculos Estadísticos**: Calcularemos la mediana y la desviación estándar de las ventas totales por tienda. Para ello, convertiremos la columna de ingresos a un array de Numpy.\n",
    "2.  **Simulación de Ventas**: Generaremos una simulación de proyecciones de ventas futuras utilizando arrays aleatorios de Numpy. Estableceremos una semilla (`seed`) para garantizar que los resultados sean reproducibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convertir la columna de ingresos totales a un array de Numpy\n",
    "ventas_array = ventas_por_tienda['ingresos_totales'].to_numpy()\n",
    "\n",
    "# Calcular la mediana y la desviación estándar\n",
    "mediana_ventas = np.median(ventas_array)\n",
    "desviacion_estandar_ventas = np.std(ventas_array)\n",
    "\n",
    "print(\"--- Cálculos Estadísticos con NumPy ---\")\n",
    "print(f\"Mediana de las ventas totales por tienda: ${mediana_ventas:,.2f}\")\n",
    "print(f\"Desviación estándar de las ventas totales por tienda: ${desviacion_estandar_ventas:,.2f}\")\n",
    "\n",
    "# 2. Simular proyecciones de ventas futuras para los próximos 6 meses\n",
    "# Usamos la media y desviación estándar de las ventas actuales para la simulación\n",
    "np.random.seed(42)  # Semilla para reproducibilidad\n",
    "media_ventas = ventas_array.mean()\n",
    "num_tiendas = len(ventas_por_tienda)\n",
    "num_meses = 6\n",
    "\n",
    "# Generar proyecciones usando una distribución normal\n",
    "proyecciones_ventas = np.random.normal(loc=media_ventas, scale=desviacion_estandar_ventas, size=(num_meses, num_tiendas))\n",
    "\n",
    "# Convertir a DataFrame para una mejor visualización\n",
    "df_proyecciones = pd.DataFrame(\n",
    "    proyecciones_ventas, \n",
    "    columns=[f\"Tienda_{id}\" for id in ventas_por_tienda['tienda_id']],\n",
    "    index=[f\"Mes_{i+1}\" for i in range(num_meses)]\n",
    ")\n",
    "\n",
    "print(\"\\n--- Proyección de Ventas Simuladas para los Próximos 6 Meses ---\")\n",
    "print(df_proyecciones.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusiones del Análisis\n",
    "\n",
    "Este análisis ha proporcionado una visión integral del rendimiento de la red de tiendas de RetailNow. Los principales hallazgos son:\n",
    "\n",
    "- **Rendimiento de Ventas**: Se ha cuantificado el rendimiento de ventas por tienda, producto y categoría, identificando las áreas de mayor y menor ingreso.\n",
    "- **Gestión de Inventario**: Se han detectado productos con una rotación inferior al 10% en ciertas tiendas, lo que sugiere una oportunidad para optimizar el stock y evitar costos de almacenamiento innecesarios.\n",
    "- **Satisfacción del Cliente**: Se han identificado las tiendas con una satisfacción inferior al 60%. Existe una correlación entre la baja satisfacción y un rendimiento de ventas moderado, lo que indica que mejorar la experiencia del cliente podría impulsar los ingresos.\n",
    "- **Proyecciones**: Las simulaciones con Numpy ofrecen un escenario base para establecer objetivos de ventas futuros y evaluar el rendimiento a lo largo del tiempo.\n",
    "\n",
    "Las recomendaciones estratégicas se centran en investigar las causas de la baja satisfacción y el inventario crítico en las tiendas señaladas para desarrollar planes de acción específicos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
